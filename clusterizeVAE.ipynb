{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N8nWw2WNqJ8u"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "import dataparsing\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLtQN5xgqJ8v"
   },
   "source": [
    "# Initialize wandb and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kGSSVDKeqJ8v"
   },
   "outputs": [],
   "source": [
    "train_dataset = dataparsing.AugmentedDataset(dataparsing.train, transforms=True)\n",
    "test_dataset = dataparsing.AugmentedDataset(dataparsing.test, transforms=True)\n",
    "val_dataset = dataparsing.AugmentedDataset(dataparsing.val, transforms=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qws8z9Q0qJ8v"
   },
   "source": [
    "# Define Vae "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = [0, 0, 0, 0]\n",
    "def get_corner_vectors(dimension):\n",
    "    corners = []\n",
    "    corner1 = torch.ones(dimension)\n",
    "    corner2 = -torch.ones(dimension)\n",
    "\n",
    "    corner3 = torch.empty(dimension)\n",
    "    corner4 = torch.empty(dimension)\n",
    "    for i in range(dimension):\n",
    "        if i % 2 == 0:\n",
    "            corner3[i] = 1\n",
    "            corner4[i] = -1\n",
    "        else:\n",
    "            corner3[i] = -1\n",
    "            corner4[i] = 1\n",
    "    scale_factor = 5.0\n",
    "    corners = [corner1 * scale_factor, corner2 * scale_factor, corner3 * scale_factor, corner4 * scale_factor]\n",
    "\n",
    "    return [c.to(device) for c in corners]\n",
    "cluster_centers = get_corner_vectors(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, n_heads, embd_dim, in_proj_bias=True, out_proj_bias=True):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.in_proj = nn.Linear(embd_dim, 3 * embd_dim, bias=in_proj_bias)\n",
    "        self.out_proj = nn.Linear(embd_dim, embd_dim, bias=out_proj_bias)\n",
    "        self.d_heads = embd_dim // n_heads\n",
    "    def forward(self, x, casual_mask=False):\n",
    "        batch_size, seq_len, d_embed = x.shape\n",
    "        interim_shape = (batch_size, seq_len, self.n_heads, self.d_heads)\n",
    "        q, k, v = self.in_proj(x).chunk(3, dim=-1)\n",
    "        q = q.view(interim_shape)\n",
    "        k = k.view(interim_shape)\n",
    "        v = v.view(interim_shape)\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "        weight = q @ k.transpose(-1, -2)\n",
    "        if casual_mask:\n",
    "            mask = torch.ones_like(weight, dtype=torch.bool).triu(1)\n",
    "            weight.masked_fill_(mask, -torch.inf)\n",
    "        weight /= math.sqrt(self.d_heads)\n",
    "        weight = F.softmax(weight, dim=-1)\n",
    "        output = weight @ v\n",
    "        output = output.transpose(1, 2)\n",
    "        output = output.reshape((batch_size, seq_len, d_embed))\n",
    "        output = self.out_proj(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.groupnorm = nn.GroupNorm(32, channels)\n",
    "        self.attention = SelfAttention(1, channels)\n",
    "    def forward(self, x):\n",
    "        residual = x.clone()\n",
    "        x = self.groupnorm(x)\n",
    "        n, c, h, w = x.shape\n",
    "        x = x.view((n, c, h * w))\n",
    "        x = x.transpose(-1, -2)\n",
    "        x = self.attention(x)\n",
    "        x = x.transpose(-1, -2)\n",
    "        x = x.view((n, c, h, w))\n",
    "        x += residual\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.groupnorm1 = nn.GroupNorm(32, in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.groupnorm2 = nn.GroupNorm(32, out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        if in_channels == out_channels:\n",
    "            self.residual_layer = nn.Identity()\n",
    "        else:\n",
    "            self.residual_layer = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0)\n",
    "    def forward(self, x):\n",
    "        residue = x.clone()\n",
    "        x = self.groupnorm1(x)\n",
    "        x = F.selu(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.groupnorm2(x)\n",
    "        x = self.conv2(x)\n",
    "        return x + self.residual_layer(residue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
    "            ResidualBlock(128, 128),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=0),\n",
    "            ResidualBlock(128, 256),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=0),\n",
    "            ResidualBlock(256, 512),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=0),\n",
    "            AttentionBlock(512),\n",
    "            ResidualBlock(512, 512),\n",
    "            nn.GroupNorm(32, 512),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(512, 8, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(8, 8, kernel_size=1, padding=0)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        for module in self:\n",
    "            if isinstance(module, nn.Conv2d) and module.stride == (2, 2):\n",
    "                x = F.pad(x, (0, 1, 0, 1))\n",
    "            x = module(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(4, 512, kernel_size=3, padding=1),\n",
    "            ResidualBlock(512, 512),\n",
    "            AttentionBlock(512),\n",
    "            ResidualBlock(512, 512),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            ResidualBlock(512, 512),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            ResidualBlock(512, 256),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            ResidualBlock(256, 128),\n",
    "            nn.GroupNorm(32, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(128, 3, kernel_size=3, padding=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x /= 0.18215\n",
    "        for module in self:\n",
    "            x = module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FEPmsnWgNN4o"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.mu = nn.Linear(512, 128)\n",
    "        self.logvar = nn.Linear(512, 128)\n",
    "        self.restarter = nn.Linear(128, 256)\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        encoded = encoded.view(encoded.size(0), -1)\n",
    "        mean = self.mu(encoded)\n",
    "        log_variance = self.logvar(encoded)\n",
    "        log_variance = torch.clamp(log_variance, -30, 20)\n",
    "        std = torch.exp(0.5 * log_variance)\n",
    "        eps = torch.randn_like(std)\n",
    "        mean = mean + eps * std\n",
    "        restarted = self.restarter(mean)\n",
    "        restarted = restarted.view(restarted.size(0), 4, 8, 8)\n",
    "        decoded = self.decoder(restarted)\n",
    "        return decoded, mean, log_variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2fEE0413qJ8v"
   },
   "outputs": [],
   "source": [
    "vae = VAE()\n",
    "vae.to(device)\n",
    "optimizer = torch.optim.AdamW(vae.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0YKzccmqJ8v"
   },
   "source": [
    "# Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RKbCLa2rqJ8v"
   },
   "outputs": [],
   "source": [
    "def loss_function(mu, y, recon_x, x):\n",
    "    # mu: [batch_size, latent_dim], y: [batch_size] with values in [0..L-1]\n",
    "    centers = torch.stack(cluster_centers).to(mu.device)        # [L, latent_dim]\n",
    "    distances = torch.cdist(mu, centers)                       # [batch_size, L]\n",
    "\n",
    "    # invert distances to get logits; add eps to avoid div0\n",
    "    total_dist = distances.sum(dim=1, keepdim=True)            # [batch_size, 1]\n",
    "    logits = (total_dist - distances) / (total_dist + 1e-8)    # [batch_size, L]\n",
    "\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    preds = logits.argmax(dim=1)\n",
    "    acc  = (preds == y).float().mean()\n",
    "    mse_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    loss += mse_loss * 0.00001\n",
    "    return loss, acc\n",
    "\n",
    "# Function to sample anchor, positive, negative triplets within a batch\n",
    "def sample_triplets(mu, labels):\n",
    "    anchors, positives, negatives = [], [], []\n",
    "    device = mu.device  # Get the device of the mu tensor\n",
    "    for i in range(mu.size(0)):\n",
    "        anchor, label = mu[i], labels[i]\n",
    "        # Ensure the index tensor is on the same device as mu\n",
    "        positive_indices = (labels == label) & (torch.arange(mu.size(0), device=device) != i)\n",
    "        negative_indices = labels != label\n",
    "        positive = mu[positive_indices]\n",
    "        negative = mu[negative_indices]\n",
    "\n",
    "        if len(positive) > 0 and len(negative) > 0:\n",
    "            pos_sample = positive[torch.randint(len(positive), (1,), device=device)]\n",
    "            neg_sample = negative[torch.randint(len(negative), (1,), device=device)]\n",
    "            anchors.append(anchor)\n",
    "            positives.append(pos_sample.squeeze(0))\n",
    "            negatives.append(neg_sample.squeeze(0))\n",
    "    if len(anchors) > 0:\n",
    "        return torch.stack(anchors), torch.stack(positives), torch.stack(negatives)\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oez0iKYmqJ8v"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "gDEKzDiubkku",
    "outputId": "47de2a82-b939-44f1-871d-48c7cc11d633"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training: 100%|██████████| 1819/1819 [05:20<00:00,  5.68it/s]\n",
      "Epoch 1 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.61it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.019793559..1.0267051].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.01352371..0.9410879].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.015502038..0.89859116].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.019507084..0.95978993].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.009365729..0.88491064].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0050186887..0.957394].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0057600876..0.91534066].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0063290372..0.94930696].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.008067141..0.9172565].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0047207437..1.015374].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.014214599..0.8762026].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.014629624..0.81280994].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0039413013..0.9030781].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.03139021..0.9266853].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.011517111..0.9150604].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3718013155009738, Train Acc: 0.5398625135421753, Val Loss: 1.3673725184472352, Val Acc: 0.5353407263755798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 1819/1819 [05:20<00:00,  5.67it/s]\n",
      "Epoch 2 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.52it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.012777794..0.9806065].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.014203019..0.5395645].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0038332548..1.0283058].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.006150985..0.882353].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.006701395..1.007824].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.014931789..1.0070276].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0056315884..1.0375355].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00699779..1.0343394].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.350092654703409, Train Acc: 0.581134021282196, Val Loss: 1.3501503845024412, Val Acc: 0.5793977975845337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training: 100%|██████████| 1819/1819 [05:21<00:00,  5.66it/s]\n",
      "Epoch 3 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.49it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.013369761..0.7311668].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0053419396..0.9263864].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.021733388..0.7800881].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0031787157..0.86840236].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.027555563..1.0931821].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.013667569..0.84882957].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3441262072795854, Train Acc: 0.599518895149231, Val Loss: 1.3431596329775175, Val Acc: 0.5860539078712463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training: 100%|██████████| 1819/1819 [05:20<00:00,  5.67it/s]\n",
      "Epoch 4 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.53it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.028914787..0.8280055].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.011190504..0.86688894].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.04795467..0.89324653].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.020062566..0.96107095].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.012930527..0.8229044].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.009480245..0.9614991].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.03397619..0.859776].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.031152733..0.6501969].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3381365344614506, Train Acc: 0.6115463972091675, Val Loss: 1.3397066224773788, Val Acc: 0.6009508967399597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training: 100%|██████████| 1819/1819 [05:20<00:00,  5.67it/s]\n",
      "Epoch 5 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.56it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.020325687..1.0011487].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.023981832..0.5878866].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.017531224..1.0042566].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.023813091..1.0111263].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.003814824..0.80205345].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.008875251..1.0082134].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3334470724649856, Train Acc: 0.6219587326049805, Val Loss: 1.3361115753745125, Val Acc: 0.5996830463409424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training: 100%|██████████| 1819/1819 [05:20<00:00,  5.68it/s]\n",
      "Epoch 6 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.56it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.002039045..0.8647778].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.02087468..0.6410583].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.01790478..0.8237612].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3282045903156714, Train Acc: 0.6354638934135437, Val Loss: 1.3322064587884772, Val Acc: 0.6110935211181641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.70it/s]\n",
      "Epoch 7 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.61it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.011555396..0.9640763].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.013068296..0.9629792].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3227982569068568, Train Acc: 0.6477319598197937, Val Loss: 1.3236953066948287, Val Acc: 0.6288431286811829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.69it/s]\n",
      "Epoch 8 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.54it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.032979302..1.0534216].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0043025017..1.005787].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.029961102..1.0225594].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3176549405494506, Train Acc: 0.6526460647583008, Val Loss: 1.3232243110563033, Val Acc: 0.6342313885688782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training: 100%|██████████| 1819/1819 [05:20<00:00,  5.68it/s]\n",
      "Epoch 9 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.55it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.024895616..1.2741402].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.009127207..1.306662].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0042705685..1.0647106].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.006073728..1.338737].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.014757801..1.0049006].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3121635159266363, Train Acc: 0.6634708046913147, Val Loss: 1.3155067799775233, Val Acc: 0.6437401175498962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.69it/s]\n",
      "Epoch 10 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.60it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.024719529..1.1646498].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.02358777..1.252115].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.011679336..0.73216426].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3088364850368697, Train Acc: 0.6704810857772827, Val Loss: 1.3100061729101673, Val Acc: 0.6573692560195923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.69it/s]\n",
      "Epoch 11 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.58it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.02430439..0.9623454].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0029982328..0.7880899].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.03037244..0.8969172].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0019244403..0.8900081].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.008131698..1.1062369].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.017742492..1.0709511].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3050435898639903, Train Acc: 0.67608243227005, Val Loss: 1.3210487396327895, Val Acc: 0.6247226595878601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.70it/s]\n",
      "Epoch 12 - Validation: 100%|██████████| 395/395 [00:33<00:00, 11.62it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.010359261..1.0823208].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.016589023..0.94241583].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.013372526..1.0482416].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.004692219..1.0774881].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0022822246..1.2367085].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0042455494..1.0501481].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.009899557..0.9018744].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.303055031193081, Train Acc: 0.6791752576828003, Val Loss: 1.3149051372298348, Val Acc: 0.632012665271759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.70it/s]\n",
      "Epoch 13 - Validation: 100%|██████████| 395/395 [00:33<00:00, 11.66it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.016596891..1.0231122].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0042883605..0.9620465].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.02961132..1.0621701].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3030179630194334, Train Acc: 0.6781099438667297, Val Loss: 1.3024774609579337, Val Acc: 0.6787638664245605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.70it/s]\n",
      "Epoch 14 - Validation: 100%|██████████| 395/395 [00:33<00:00, 11.69it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0040461496..0.9168049].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.018217944..0.8744639].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.005465299..1.1249925].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0004730299..0.9271643].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0026982203..0.96507275].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.01615341..1.1388046].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.009168647..1.0141399].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0031697378..0.9886656].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.004602723..0.993379].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3001201791206176, Train Acc: 0.6874226927757263, Val Loss: 1.302420350715589, Val Acc: 0.6651347279548645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Training: 100%|██████████| 1819/1819 [05:18<00:00,  5.70it/s]\n",
      "Epoch 15 - Validation: 100%|██████████| 395/395 [00:33<00:00, 11.65it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.028359015..1.0472072].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.024582699..1.1399509].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.025986299..1.1147372].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.024438553..1.0212569].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.027710602..1.0687745].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.02391915..1.1061499].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.025408618..1.2709565].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2977869590123494, Train Acc: 0.6885223388671875, Val Loss: 1.2955660300851812, Val Acc: 0.6976228356361389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.70it/s]\n",
      "Epoch 16 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.60it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.021806344..1.0777278].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.02391868..1.0385299].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.02804067..1.0321066].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.017574526..1.1636724].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0147507265..1.1600041].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2949812211531544, Train Acc: 0.6965292096138, Val Loss: 1.3029148317932515, Val Acc: 0.6645007729530334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.70it/s]\n",
      "Epoch 17 - Validation: 100%|██████████| 395/395 [00:33<00:00, 11.62it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0087580085..1.0688579].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.01920963..1.1354301].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.015854836..1.1240218].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.020792961..1.0064476].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.012388542..1.090394].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2956144052682463, Train Acc: 0.6940549612045288, Val Loss: 1.2956167335177753, Val Acc: 0.6847860813140869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.69it/s]\n",
      "Epoch 18 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.55it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.012693003..1.257998].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.024628893..1.1089541].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.293179385375321, Train Acc: 0.69924396276474, Val Loss: 1.3013622514797276, Val Acc: 0.6591125130653381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Training: 100%|██████████| 1819/1819 [05:20<00:00,  5.68it/s]\n",
      "Epoch 19 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.59it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.027288213..1.0400431].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2930468230886558, Train Acc: 0.6981787085533142, Val Loss: 1.2915120324317702, Val Acc: 0.7074484825134277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Training: 100%|██████████| 1819/1819 [05:18<00:00,  5.70it/s]\n",
      "Epoch 20 - Validation: 100%|██████████| 395/395 [00:33<00:00, 11.72it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.032593235..1.0515723].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.027128942..1.0910408].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.021034546..1.041328].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.01889012..1.1051387].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2906151928852514, Train Acc: 0.7025772929191589, Val Loss: 1.2926142225930506, Val Acc: 0.6906497478485107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Training: 100%|██████████| 1819/1819 [05:18<00:00,  5.70it/s]\n",
      "Epoch 21 - Validation: 100%|██████████| 395/395 [00:33<00:00, 11.63it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.024352878..1.0608157].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.291559096693583, Train Acc: 0.6988316178321838, Val Loss: 1.3178574593055834, Val Acc: 0.6291600465774536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.70it/s]\n",
      "Epoch 22 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.59it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.015895873..1.0167497].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2899359806460613, Train Acc: 0.7059793472290039, Val Loss: 1.288505460985489, Val Acc: 0.7055467367172241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.69it/s]\n",
      "Epoch 23 - Validation: 100%|██████████| 395/395 [00:33<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2884615975638845, Train Acc: 0.706804096698761, Val Loss: 1.299854826624911, Val Acc: 0.6524564027786255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.69it/s]\n",
      "Epoch 24 - Validation: 100%|██████████| 395/395 [00:33<00:00, 11.65it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.031568117..1.017532].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.02839154..1.0066992].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.287456279505569, Train Acc: 0.7077662944793701, Val Loss: 1.2902550299080728, Val Acc: 0.6976228356361389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.70it/s]\n",
      "Epoch 25 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.60it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0034249425..0.9342385].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2871981182786607, Train Acc: 0.7064604759216309, Val Loss: 1.2950851180851932, Val Acc: 0.678288459777832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.70it/s]\n",
      "Epoch 26 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.58it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.021980248..1.0011039].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2853202187974018, Train Acc: 0.7113058567047119, Val Loss: 1.3021159743733717, Val Acc: 0.6385102868080139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.70it/s]\n",
      "Epoch 27 - Validation: 100%|██████████| 395/395 [00:33<00:00, 11.64it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.008517966..1.0241716].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.286870535624396, Train Acc: 0.7070790529251099, Val Loss: 1.2913737291012626, Val Acc: 0.689540445804596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.69it/s]\n",
      "Epoch 28 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.56it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.026625477..1.0342276].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.017549843..0.90348685].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.00845851..0.6320876].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2860530628289553, Train Acc: 0.7093126773834229, Val Loss: 1.2992936889645414, Val Acc: 0.6510301232337952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.69it/s]\n",
      "Epoch 29 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.28415377017149, Train Acc: 0.7146391868591309, Val Loss: 1.2865140529895547, Val Acc: 0.7099841833114624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Training: 100%|██████████| 1819/1819 [05:19<00:00,  5.69it/s]\n",
      "Epoch 30 - Validation: 100%|██████████| 395/395 [00:34<00:00, 11.60it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.03312549..0.9654236].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0036900267..1.0147707].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.010211468..1.0180722].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.010369092..0.93442184].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0061763376..0.6185344].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2818181074607824, Train Acc: 0.722542941570282, Val Loss: 1.2880555475948352, Val Acc: 0.7028526067733765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 - Training:  62%|██████▏   | 1125/1819 [03:21<02:04,  5.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m loss.backward()\n\u001b[32m     16\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * inputs.size(\u001b[32m0\u001b[39m)\n\u001b[32m     19\u001b[39m running_acc += accuracy * inputs.size(\u001b[32m0\u001b[39m)\n\u001b[32m     20\u001b[39m total_samples += inputs.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(40):\n",
    "    vae.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\"):\n",
    "        inputs = batch[0].to(device)\n",
    "        labels = batch[1].to(device) # Get labels for loss calculation\n",
    "        optimizer.zero_grad()\n",
    "        recon_x, mu, logvar = vae(inputs)\n",
    "        # Use the fixed cluster_centers in the loss function\n",
    "        loss, accuracy = loss_function(mu, labels, recon_x, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_acc += accuracy * inputs.size(0)\n",
    "        total_samples += inputs.size(0)\n",
    "\n",
    "\n",
    "    avg_train_loss = running_loss / total_samples\n",
    "\n",
    "    # Validation loop\n",
    "    vae.eval()\n",
    "    running_val_loss = 0.0\n",
    "    running_acc_eval = 0.0\n",
    "    total_val_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} - Validation\"):\n",
    "            inputs = batch[0].to(device)\n",
    "            labels = batch[1].to(device) # Get labels for loss calculation\n",
    "            recon_x, mu, logvar = vae(inputs)\n",
    "            # Use the fixed cluster_centers in the loss function\n",
    "            loss, acc = loss_function(mu, labels, recon_x, inputs)\n",
    "            running_val_loss += loss.item() * inputs.size(0)\n",
    "            running_acc_eval += acc * inputs.size(0)\n",
    "            total_val_samples += inputs.size(0)\n",
    "\n",
    "    avg_val_loss = running_val_loss / total_val_samples\n",
    "\n",
    "\n",
    "    # Save a sample input and its reconstruction as an image\n",
    "    vae.eval()\n",
    "    sample_batch = next(iter(val_loader))\n",
    "    sample_input = sample_batch[0].to(device)\n",
    "    with torch.no_grad():\n",
    "        sample_output, _, _ = vae(sample_input)\n",
    "    sample_input = sample_input.cpu().numpy()\n",
    "    sample_output = sample_output.cpu().numpy()\n",
    "\n",
    "    num_samples = min(20, sample_input.shape[0])\n",
    "    fig, axs = plt.subplots(2, num_samples, figsize=(num_samples * 2, 4))\n",
    "    for i in range(num_samples):\n",
    "        # Input image\n",
    "        axs[0, i].imshow(sample_input[i].transpose(1, 2, 0))\n",
    "        axs[0, i].axis(\"off\")\n",
    "        # Reconstructed image\n",
    "        axs[1, i].imshow(sample_output[i].transpose(1, 2, 0))\n",
    "        axs[1, i].axis(\"off\")\n",
    "    plt.savefig(f\"vae_reconstructions/epoch_{epoch+1}.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss}, Train Acc: {running_acc / total_samples}, Val Loss: {avg_val_loss}, Val Acc: {running_acc_eval / total_val_samples}\")\n",
    "\n",
    "    torch.save(vae, 'VAEModelCubicFit.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "radiowaves",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
