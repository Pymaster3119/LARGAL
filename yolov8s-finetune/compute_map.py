import json
from pathlib import Path
import argparse
import sys
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval



def read_yolo_labels(label_path: Path, img_w: int, img_h: int):
	boxes = []
	if not label_path.exists():
		return boxes
	for line in label_path.read_text().splitlines():
		line = line.strip()
		if not line:
			continue
		parts = line.split()
		if len(parts) < 5:
			continue
		cls = int(float(parts[0]))
		x_c = float(parts[1])
		y_c = float(parts[2])
		w = float(parts[3])
		h = float(parts[4])
		x1 = int(round((x_c - w / 2.0) * img_w))
		y1 = int(round((y_c - h / 2.0) * img_h))
		x2 = int(round((x_c + w / 2.0) * img_w))
		y2 = int(round((y_c + h / 2.0) * img_h))
		boxes.append((cls, x1, y1, x2, y2))
	return boxes


def clamp_box(x1, y1, x2, y2, w, h):
	x1 = max(0, min(w - 1, int(x1)))
	y1 = max(0, min(h - 1, int(y1)))
	x2 = max(0, min(w, int(x2)))
	y2 = max(0, min(h, int(y2)))
	return x1, y1, x2, y2


def build_gt_coco(data_root: Path):
	# accept either a Path or a string for data_root
	data_root = Path(data_root)
	images_dir = data_root / 'images' / 'val'
	labels_dir = data_root / 'labels' / 'val'
	imgs = sorted([p for p in images_dir.iterdir() if p.suffix.lower() in ('.png', '.jpg', '.jpeg')])

	images_out = []
	annotations_out = []
	categories_seen = set()
	image_id = 0
	ann_id = 1

	from PIL import Image

	for img_path in imgs:
		try:
			with Image.open(img_path) as im:
				w, h = im.size
		except Exception:
			# fallback to OpenCV if PIL not available
			import cv2
			im = cv2.imread(str(img_path))
			if im is None:
				continue
			h, w = im.shape[:2]

		image_id += 1
		images_out.append({'id': image_id, 'file_name': img_path.name, 'width': w, 'height': h})

		gt_file = labels_dir / (img_path.stem + '.txt')
		gt_boxes = read_yolo_labels(gt_file, w, h)
		for i, (cls, x1, y1, x2, y2) in enumerate(gt_boxes):
			x1, y1, x2, y2 = clamp_box(x1, y1, x2, y2, w, h)
			if x2 <= x1 or y2 <= y1:
				continue
			w_box = x2 - x1
			h_box = y2 - y1
			# only keep medium+large boxes (filter small objects)
			area_box = int(w_box * h_box)
			annotations_out.append({
				'id': ann_id,
				'image_id': image_id,
				'category_id': int(cls),
				'bbox': [int(x1), int(y1), int(w_box), int(h_box)],
				'area': area_box,
				'iscrowd': 0
			})
			categories_seen.add(int(cls))
			ann_id += 1

	categories_out = [{'id': int(cid), 'name': str(cid)} for cid in sorted(categories_seen)]

	gt_dict = {
		'info': {'description': 'gt generated by compute_map.py'},
		'licenses': [],
		'images': images_out,
		'annotations': annotations_out,
		'categories': categories_out
	}
	return gt_dict


def main(conf):
	# paths (use Path objects so we can call .mkdir() / .open() reliably)
	pred_json = Path('/Users/aditya/Desktop/InProgress/Radio Galaxies/dataset/predictions/predictions.json')

	# Build GT COCO dict (build_gt_coco accepts str or Path)
	gt = build_gt_coco('/Users/aditya/Desktop/InProgress/Radio Galaxies/dataset/')

	# write GT temporary file
	annotations_dir = Path('/Users/aditya/Desktop/InProgress/Radio Galaxies/dataset/annotations')
	annotations_dir.mkdir(parents=True, exist_ok=True)
	gt_path = annotations_dir / 'gt_temp_eval.json'
	with gt_path.open('w', encoding='utf-8') as f:
		json.dump(gt, f)

	cocoGt = COCO(str(gt_path))

	# Load predictions JSON
	with pred_json.open('r', encoding='utf-8') as f:
		pred_obj = json.load(f)

	# predictions may be dict with 'annotations' or a list
	if isinstance(pred_obj, dict) and 'annotations' in pred_obj:
		dets = pred_obj['annotations']
	elif isinstance(pred_obj, list):
		dets = pred_obj
	else:
		raise RuntimeError('Prediction JSON must be either a list of detections or a dict with "annotations"')


	# COCO expects categories to be present in GT; predictions are a list of {image_id, category_id, bbox, score}
	cocoDt = cocoGt.loadRes(dets)

	cocoEval = COCOeval(cocoGt, cocoDt, iouType='bbox')
	cocoEval.evaluate()
	cocoEval.accumulate()
	cocoEval.summarize()

	# stats: 0->AP @[.5:.95], 1->AP@0.5, 2->AP@0.75, 3->AP (small), ...
	stats = getattr(cocoEval, 'stats', None)
	if stats is not None:
		print('\nSummary metrics:')
		print(f'mAP (AP@[.5:.95]): {stats[0]:.4f}')
		print(f'mAP@0.5: {stats[1]:.4f}')
		print(f'mAP@0.75: {stats[2]:.4f}')
		print(f'AP (small): {stats[3]:.4f}')
		print(f'AP (medium): {stats[4]:.4f}')
		print(f'AP (large): {stats[5]:.4f}')

		# Print out the size needed to be classified as small/medium/large
		print('\nCOCO size definitions:')
		print('Small: area < 32^2 = 1024')
		print('Medium: 32^2 <= area < 96^2 = 9216')
		print('Large: area >= 96^2 = 9216')
	return stats[0]
	


if __name__ == '__main__':
	main(0.001)

